# ğŸ›¡ï¸ ToxiGuard AI

ToxiGuard AI is a **real-time toxic content detection platform** built using:

- âš›ï¸ React (Vite) â€” Premium frontend UI
- ğŸš€ FastAPI â€” High-performance backend API
- ğŸ§  Machine Learning â€” TF-IDF + Logistic Regression
- ğŸ¤– LLM (OpenRouter) â€” Context-aware moderation
- ğŸ“Š Analytics â€” KPI, charts, history, word cloud

It detects abusive language, estimates toxicity, provides explanations, and visual analytics.

---

## ğŸ“ Project Structure

ToxiGuard-AI/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ train_model.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”œâ”€â”€ abuse_model.joblib
â”‚ â”œâ”€â”€ label_encoder.joblib
â”‚ â””â”€â”€ utils/
â”‚ â”œâ”€â”€ abuse_words.py
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ sentiment.py
â”‚ â””â”€â”€ llm_guard.py
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ package.json
â”‚ â”œâ”€â”€ vite.config.js
â”‚ â”œâ”€â”€ index.html
â”‚ â””â”€â”€ src/
â”‚ â”œâ”€â”€ main.jsx
â”‚ â”œâ”€â”€ App.jsx
â”‚ â”œâ”€â”€ api.js
â”‚ â”œâ”€â”€ styles.css
â”‚ â””â”€â”€ components/
â”‚ â”œâ”€â”€ Header.jsx
â”‚ â”œâ”€â”€ TextInput.jsx
â”‚ â”œâ”€â”€ LiveResult.jsx
â”‚ â”œâ”€â”€ KPI.jsx
â”‚ â”œâ”€â”€ Charts.jsx
â”‚ â”œâ”€â”€ AbuseTable.jsx
â”‚ â”œâ”€â”€ History.jsx
â”‚ â””â”€â”€ WordClouds.jsx
â”‚
â””â”€â”€ README.md


---

## ğŸš€ Features

- âœ… Live toxic word detection
- âœ… ML-based classification (97%+ accuracy)
- âœ… LLM fallback for contextual understanding
- âœ… Highlight abusive words
- âœ… KPI dashboard (words, abusive count, toxicity)
- âœ… Pie chart and toxicity bar
- âœ… Abuse table with CSV export
- âœ… Word cloud visualization
- âœ… Analysis history
- âœ… Premium glassmorphism UI

---

## ğŸ§© Backend Setup

### 1ï¸âƒ£ Create virtual environment (recommended)

```bash
cd backend
python -m venv venv
venv\Scripts\activate   # Windows
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Environment variables
Create file:

backend/.env
Add:

OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_MODEL=xiaomi/mimo-v2-flash:free
4ï¸âƒ£ Train ML model (only once)
python train_model.py
This generates:

abuse_model.joblib
label_encoder.joblib
5ï¸âƒ£ Run backend
Option A (recommended):

python main.py
Option B:

uvicorn app:app --host 0.0.0.0 --port 8090 --reload
Backend runs at:

http://127.0.0.1:8090
Swagger API:

http://127.0.0.1:8090/docs
âš›ï¸ Frontend Setup
1ï¸âƒ£ Install dependencies
cd frontend
npm install
2ï¸âƒ£ Start frontend
npm run dev
Open browser:

http://localhost:5173
â–¶ï¸ Restart Frontend
If UI breaks or new components are added:

npm run dev
(Stop previous process using CTRL + C if needed.)

ğŸ”— API Usage
Endpoint
POST /predict
Request
{
  "text": "you are stupid"
}
Response
{
  "toxic": true,
  "confidence": 0.95,
  "severity": "high",
  "reason": "Matched abusive keywords",
  "abusive_words": ["stupid"],
  "word_frequency": { "stupid": 1 },
  "suggestions": { "stupid": "Use 'unwise' instead." },
  "sentiment": {
    "label": "negative",
    "polarity": -0.6,
    "confidence": 0.6
  },
  "source": "rules"
}
âš ï¸ Common Issues & Fixes
âŒ Port not opening
Run backend again:

python main.py
Open:

http://127.0.0.1:8090
âŒ Dependency conflicts (Node)
If frontend fails:

npm cache clean --force
npm install
npm run dev
Recommended Node version:

Node 18 LTS
âŒ ML model not loading
If you see:

ML model load failed
Run:

python train_model.py
âŒ CORS error
Ensure backend is running before frontend.

ğŸ“¦ Production Build
npm run build
Output folder:

frontend/dist
ğŸ‘¨â€ğŸ’» Author
Developed by Saurabh Yadav.

ğŸ“œ License
MIT License